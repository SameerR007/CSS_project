<a name="br1"></a> 

New York Times Bestseller Analysis

Sameer Singh Rawat, LMU



<a name="br2"></a> 

Overview

● Dataset - The data will comprise of the book titles and their respective

summary. This will be generated by NYT api.

● Sentiment analysis will be done on the summary.

● Topic modelling will be done on the summary but since summaries only

describe in short detail, the descriptions will be fetched by google book api

and topic modelling will be done on both.

● Recommendation - the columns such as authors, genres will be fetched

through api and content based recommendation will be done based on the

book user has already read.



<a name="br3"></a> 

Dataset

1\. Dataset will comprise of the books that has featured as NYT bestseller at the

start of each month of 2023.

2\. Dataset will contain the information about the books such as their author,

genres, short description( referred as summary), detailed description (referred

as description).

3\. The difference between summary and description of random three can be

seen in the figure on the next slide.

4\. Since summary seems to focus on solely the story of the book it is wise to

perform sentiment analysis on them while description is more elaborative in

size it seems better to do topic modelling on description.



<a name="br4"></a> 

Summary VS Description



<a name="br5"></a> 

Sentiment Analysis

● Sentiment analysis will be done by state of art model BERT and also through

a trained from scratch RNN model.

● RNN model is trained on the X(Twitter) dataset taken from kaggle. The

dataset is divided into 80:20 train and test.

● This model gives a test set accuracy of about 80%.

● The predictions of sentiments of summary of total dataset with BERT model

and RNN can be seen in the form of count plot in the next slide.

● RNN seems to struggle with classifying the sentiment of summaries in black

and white,mostly outputting grey(neutral). While BERT mostly classifies the

books to be of positive sentiment.(Figure on the next slide)



<a name="br6"></a> 

BERT VS RNN



<a name="br7"></a> 

Topic Modelling

● It will determine the topics around which people like to read stories.

● Again this will be done by state of art model BERTopic and a model

implemented from scratch making use of Latent Dirichlet Allocation(LDA).

● Topics derived from BERTopic will be displayed on the recommended book as

keywords.

● Topic modelling will also be done by LDA from scratch and the concept of

how LDA is trained will be discussed (yet to be done)

● Discussion on both the approaches will be done.



<a name="br8"></a> 

BERTopic on summaries (short description)

Probable themes - fantasy(Topic 0), family(Topic 1),politics(Topic 3), art(Topic 6)



<a name="br9"></a> 

BERTopic on description

Probable themes - crime(Topic 0), fantasy(Topic 1),kafka(Topic 3),

fantasy+children (Topic 6), positive sentiments such as love and hope(Topic 7)



<a name="br10"></a> 

Recommender system

In the final stage, we make a content based recommendation.

● Steps

1\. Make feature vectors combining the columns of genres, author, description for

each book and treat it as a content.

2\. When a new book is entered the feature vector is formed for this new book by

using google books api

3\. Finally the book that is most closest match to the entered book is

recommended.

NOTE - CountVectorizer is used for encoding the feature vector. And cosine similarity

for finding the closest match.



<a name="br11"></a> 

Output demo

● Similarity percent calculated by cosine similarity.

● Sentiment - as predicted by BERT

● Keywords - as suggested by BERTopic

Addition - the final model will be deployed in cloud using hugging face space and streamlit. Image of the

recommended book will also be displayed.



<a name="br12"></a> 

Thank you!

